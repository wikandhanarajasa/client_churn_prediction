# -*- coding: utf-8 -*-
"""Project Sprint 8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yig8PfzyL1iQ1pjajicRKHAsSNXQJvgf

# **Analysis of Churn Customer**

## **Introduction**

This project aim to create a machine learning model to predict wheater the client of Beta Bank will remain to stay or leave.

### **Goal**

Having a proper machine learning model to predict client churn with F1 score exceeding 0,59

### **Stages**

The stages of this project are below:

1. Load the data and study the general information.
2. Prepare the data if anomalies were found & check the class balance.
3. Create machine learning model & train the model.
4. Draw the conclusion.

### **Data Content**

The dataset consist of following columns:
    
1. Features

- RowNumber: Index of string data
- CustomerId: Customer ID
- Surname: Last name
- CreditScore: Credit score
- Geography: Country of residence
- Gender: Gender
- Age: Age
- Tenure: Duration of tenure for fixed-term customer deposits (in years)
- Balance: Account balance
- NumOfProducts: Number of bank products used by the customer
- HasCrCard: Whether the customer has a credit card (1 - yes; 0 - no)
- IsActiveMember: Customer's level of activity (1 - yes; 0 - no)
- EstimatedSalary: Estimated salary

2. Target

- Exited: Whether the customer has exited (1 - yes; 0 - no)

## **Data Loadment**
"""

# Import necessary libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
from sklearn.utils import shuffle
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix, roc_auc_score
from xgboost import XGBClassifier

# Loading dataset

path = '/content/Churn.csv'
data = pd.read_csv(path)

data.head(5)

"""## **Data Preparation**

### **Learning general information**
"""

# Data exploration

data.shape

# Retrieving information

data.info()

# Checking missing value

data.isnull().sum()

"""Comment:

1. Seems like missing value detected in column Tenure with 909 data.
2. Data type seems suitable to run machine learning
"""

# Checking duplicate value

data.duplicated().sum()

"""### **Learning distribution**

#### **Exploration Exited column**
"""

# Copying the data

data_eda = data.copy()

data_eda.head(5)

# Checking distribution of column exited

data_eda['Exited'] = data_eda['Exited'].astype(str)

data_eda['Exited'] = data_eda['Exited'].replace('0', 'Stay').replace('1', 'Exit')
data_eda.head(2)

data_eda_1 = pd.pivot_table(data_eda, index='Exited', values='RowNumber', aggfunc='count').reset_index()
data_eda_1.columns = ['Exited','Client']
data_eda_1

sns.barplot(data=data_eda_1, x='Exited', y='Client')
plt.show()

"""#### **General data exploration**"""

# Data exploration age vs exited

plt.figure(figsize=(12, 6))
sns.violinplot(data=data_eda, x='Age', y='Exited')
plt.show()

# Data exploration age vs exited

plt.figure(figsize=(12, 6))
sns.violinplot(data=data_eda, x='Balance', y='Exited')
plt.show()

data_eda['Tenure'] = data_eda['Tenure'].fillna(0)
data_eda.isnull().sum()

plt.figure(figsize=(12, 6))
sns.violinplot(data=data_eda, x='Tenure', y='Exited')
plt.show()

"""Comment:

Based on data exploratory, we can conclude that:

1. The data is not balance, where the target column has approximately 5000 data different, between stay and leave client.
2. The missing value in column tenure can be replace by 0 since it doesnt affect significantly.

### **Data Preparation**
"""

# Fill missing value in column Tenure with 0

data['Tenure'] = data['Tenure'].fillna(0)

data.isnull().sum()

# Drop unnessesary column

data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)
data.head()

# One hot encoding the categorical nominal data

data = pd.get_dummies(data=data, drop_first=True)

data.head(2)

"""Since we have a lot of data, we will have the percentage as below:

- 80% data for training set.
- 10% data for test set.
- 10% data for validation set.
"""

# Data splitting target and feature

target = data['Exited']
features = data.drop('Exited', axis=1)

features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=12)

features_val, features_test, target_val, target_test = train_test_split(features_test, target_test, test_size=0.5, random_state=12)

features_train.shape

features_test.shape

features_val.shape

"""## **Create Machine Learning Model**

Loop will be created in order to easier the process of running machine learning.

The `class_eval` function evaluates a classification model's performance on both training and test datasets by predicting target values and computing key metrics, including confusion matrices, accuracy, precision, recall, F1 score, and ROC AUC score. It then prints these metrics, offering a comprehensive overview of the model's accuracy in distinguishing between classes and balancing precision and recall. This helps in assessing the model's effectiveness and identifying issues such as bias or overfitting.
"""

def class_eval(model, features_train, features_test, target_train, target_test):
    # Predict Train
    target_train_pred = model.predict(features_train)

    # Predict Test
    target_test_pred = model.predict(features_test)

    # Show Metrics
    # Confusion Matrix
    cm_tr = confusion_matrix(target_train, target_train_pred)
    cm_te = confusion_matrix(target_test, target_test_pred)

    # Accuracy
    accuracy_tr = (cm_tr[0][0] + cm_tr[1][1]) / (cm_tr[0][0] + cm_tr[1][1] + cm_tr[0][1] + cm_tr[1][0])
    accuracy_te = (cm_te[0][0] + cm_te[1][1]) / (cm_te[0][0] + cm_te[1][1] + cm_te[0][1] + cm_te[1][0])

    # Precision
    precision_tr_1 = cm_tr[1][1] / (cm_tr[1][1] + cm_tr[0][1])
    precision_tr_0 = cm_tr[0][0] / (cm_tr[0][0] + cm_tr[1][0])
    precision_te_1 = cm_te[1][1] / (cm_te[1][1] + cm_te[0][1])
    precision_te_0 = cm_te[0][0] / (cm_te[0][0] + cm_te[1][0])

    # Recall
    recall_tr_1 = cm_tr[1][1] / (cm_tr[1][1] + cm_tr[1][0])
    recall_tr_0 = cm_tr[0][0] / (cm_tr[0][0] + cm_tr[0][1])
    recall_te_1 = cm_te[1][1] / (cm_te[1][1] + cm_te[1][0])
    recall_te_0 = cm_te[0][0] / (cm_te[0][0] + cm_te[0][1])

    # F1 Score
    f1_score_tr_1 = (2 * precision_tr_1 * recall_tr_1) / (precision_tr_1 + recall_tr_1)
    f1_score_tr_0 = (2 * precision_tr_0 * recall_tr_0) / (precision_tr_0 + recall_tr_0)
    f1_score_te_1 = (2 * precision_te_1 * recall_te_1) / (precision_te_1 + recall_te_1)
    f1_score_te_0 = (2 * precision_te_0 * recall_te_0) / (precision_te_0 + recall_te_0)

    # ROC AUC score
    roc_auc_tr = roc_auc_score(target_train, target_train_pred)
    roc_auc_te = roc_auc_score(target_test, target_test_pred)

    # Show Output
    print('----------------Training----------------')
    print('Confusion Matrix')
    print(cm_tr)
    print('Accuracy         :', round(accuracy_tr * 100, 1), '%')
    print('ROC AUC          :', round(roc_auc_tr * 100, 1), '%')
    print('Precision Class 0:', round(precision_tr_0 * 100, 1), '%')
    print('Precision Class 1:', round(precision_tr_1 * 100, 1), '%')
    print('Recall Class 0   :', round(recall_tr_0 * 100, 1), '%')
    print('Recall Class 1   :', round(recall_tr_1 * 100, 1), '%')
    print('F1 Score Class 0 :', round(f1_score_tr_0 * 100, 1), '%')
    print('F1 Score Class 1 :', round(f1_score_tr_1 * 100, 1), '%')

    print('\n----------------Testing----------------')
    print('Confusion Matrix')
    print(cm_te)
    print('Accuracy         :', round(accuracy_te * 100, 1), '%')
    print('ROC AUC          :', round(roc_auc_te * 100, 1), '%')
    print('Precision Class 0:', round(precision_te_0 * 100, 1), '%')
    print('Precision Class 1:', round(precision_te_1 * 100, 1), '%')
    print('Recall Class 0   :', round(recall_te_0 * 100, 1), '%')
    print('Recall Class 1   :', round(recall_te_1 * 100, 1), '%')
    print('F1 Score Class 0 :', round(f1_score_te_0 * 100, 1), '%')
    print('F1 Score Class 1 :', round(f1_score_te_1 * 100, 1), '%')

"""### **Logistic regression**"""

# Define Model

lr = LogisticRegression()
# Training the model

lr.fit(features_train, target_train)

class_eval(model=lr, features_train=features_train, features_test=features_test, target_train=target_train, target_test=target_test)

# Predict Validation

target_val_pred = lr.predict(features_val)

# Validation Accuracy

accuracy_score(target_val, target_val_pred)

model = LogisticRegression(random_state=12345, solver='liblinear')
model.fit = model.fit(features_val, target_val)
predicted_valid = model.predict(features_val)

print('F1 Score:', round(f1_score(target_val, predicted_valid), 2)*100, '%')

"""### **Random Forest**"""

# Define Model

rf = RandomForestClassifier(max_depth=10)
# Training the model

rf.fit(features_train, target_train)

class_eval(model=rf, features_train=features_train, features_test=features_test, target_train=target_train, target_test=target_test)

# Predict Validation

target_val_pred = rf.predict(features_val)

# Validation Accuracy

accuracy_score(target_val, target_val_pred)

model = RandomForestClassifier(max_depth=11)
model.fit = model.fit(features_val, target_val)
predicted_valid = model.predict(features_val)

print('F1 Score:', round(f1_score(target_val, predicted_valid), 2)*100, '%')

"""#### **Upsampling Method**

The `upsample` function balances class distribution by replicating minority class instances to address class imbalance. It separates features and targets into majority and minority classes, concatenates multiple copies of the minority class with the majority class, and shuffles the combined dataset for randomness. This process helps address class imbalance. The function is then used on features_train and target_train with a repeat factor of 10, producing upsampled datasets features_upsampled and target_upsampled.
"""

def upsample(features, target, repeat):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)
    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)

    features_upsampled, target_upsampled = shuffle(
        features_upsampled, target_upsampled, random_state=12345
    )

    return features_upsampled, target_upsampled


features_upsampled, target_upsampled = upsample(
    features_train, target_train, 10
)

model = RandomForestClassifier(max_depth=11)
model.fit = model.fit(features_upsampled, target_upsampled)
predicted_valid = model.predict(features_val)

print('F1:', f1_score(target_val, predicted_valid))

"""#### **Downsampling Method**

The `downsample` function balances class distribution by reducing the majority class instances to address class imbalance. It separates features and targets into majority and minority classes, samples a fraction of the majority class, concatenates these samples with the minority class, and shuffles the combined dataset for randomness. This process helps in addressing class imbalance. The function is then used on features_train and target_train with a fraction of 0.1, producing downsampled datasets features_downsampled and target_downsampled.
"""

def downsample(features, target, fraction):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    features_downsampled = pd.concat(
        [features_zeros.sample(frac=fraction, random_state=12345)]
        + [features_ones]
    )
    target_downsampled = pd.concat(
        [target_zeros.sample(frac=fraction, random_state=12345)]
        + [target_ones]
    )

    features_downsampled, target_downsampled = shuffle(
        features_downsampled, target_downsampled, random_state=12345
    )

    return features_downsampled, target_downsampled


features_downsampled, target_downsampled = downsample(
    features_train, target_train, 0.1
)

model = RandomForestClassifier(n_estimators=500, max_depth=11)
model.fit = model.fit(features_downsampled, target_downsampled)
predicted_valid = model.predict(features_val)

print('F1:', f1_score(target_val, predicted_valid))

"""Comment:

- Upscaling Method: Using Random Forest Method with hyperparameter max_depth of 11, the F1 score is 62% exceeding the requirement.
- Downscaling Method: Using Random Forest Method with hyperparameter n_estimators of 500 and max_depth of 11, the F1 score is 53%.

## **Conclusion**

1. The goal of this project is to have machine learning model that capable of having F1 score of more than 59%.
2. The data has been through several process as below:

- Filled the missing value in column tenure with 0.
- The unnecessary columns has been dropped in order to be able to run in machine learning. Those columns are: 'RowNumber', 'CustomerId' and 'Surname'.
- One hot encoding has been applied to convert the categorical data into numerical.
- Since we have a lot of data, we will have the percentage as below:

80% data for training set.
10% data for test set.
10% data for validation set.

- Loop has been created in order to easier the task to run several number of machine learning model.
- Model that has been tried are: Logistic Regression and Random Forest with the most suitable for the project objective is Random Forest with F1 score acceding 59%.
- The hyperparameret are as below:

max_depth=10,

- hyperparameter for validation test:

max_depth=11

- The result as below:

Model: Random Forest Classifier
Training Result:

- Confusion Matrix
[[6326   73]
 [ 731  870]]
- Accuracy         : 90.0 %
- ROC AUC          : 76.6 %
- Precision Class 0: 89.6 %
- Precision Class 1: 92.3 %
- Recall Class 0   : 98.9 %
- Recall Class 1   : 54.3 %
- F1 Score Class 0 : 94.0 %
- F1 Score Class 1 : 68.4 %

Testing Result:

- Confusion Matrix
[[777  17]
 [112  94]]
- Accuracy         : 87.1 %
- ROC AUC          : 71.7 %
- Precision Class 0: 87.4 %
- Precision Class 1: 84.7 %
- Recall Class 0   : 97.9 %
- Recall Class 1   : 45.6 %
- F1 Score Class 0 : 92.3 %
- F1 Score Class 1 : 59.3 %

Validation Result

- F1 Score: 96.0 %

3. Since the target column is not balance, the imbalance should be treat by using upscaling or downscaling. The both method has been tried and the result as follow:

- Upscaling Method: Using Random Forest Method with hyperparameter max_depth of 11, the F1 score is 62% exceeding the requirement.
- Downscaling Method: Using Random Forest Method with hyperparameter n_estimators of 500 and max_depth of 11, the F1 score is 53%.

3. Summary:

- The recommended machine learning model to use during the project is Random Forest with hyperparameter max_depth=10 for testing and max_depth=11 for validation to obtain F1 score more than 59% for testing and 96% for validation.
- After the balancing has been done, the recommended machine learning model to use during the project is Random Forest with hyperparameter max_depth=10 using upscaling to tacle the imbalance can result F1 score of 62% exceeding the requirement of 59%.
"""